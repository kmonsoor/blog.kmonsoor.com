<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom"><title>Khaled Monsoor :: Blog - open-source</title><link href="https://blog.kmonsoor.com/" rel="alternate"><link href="https://blog.kmonsoor.com/tag/open-source/feed/atom/index.html" rel="self"><id>https://blog.kmonsoor.com/</id><updated>2018-01-18T00:00:00+06:00</updated><entry><title>HA(High-Availability) Setup for InfluxDB</title><link href="https://blog.kmonsoor.com/ha-setup-for-influxdb/" rel="alternate"><published>2018-01-18T00:00:00+06:00</published><updated>2018-01-18T00:00:00+06:00</updated><author><name>Khaled Monsoor</name></author><id>tag:blog.kmonsoor.com,2018-01-18:/ha-setup-for-influxdb/</id><summary type="html">&lt;p&gt;Create a robust, highly-available, time-series InfluxDB cluster with community(free) version of it&lt;/p&gt;</summary><content type="html">&lt;h1&gt;HA setup for InfluxDB&lt;/h1&gt; &lt;p&gt;Currently, from version 0.9, you cannot create an InfluxDB cluster from the open-sourced free edition. Only commercially available InfluxDB Enterprise can do that for now. That stirred up the early-adopter enthusiast users, especially for their usage in professional setups. They complained that InfluxData, the company behind InfluxDB, is trying to milk the OSS solution for profit.&lt;/p&gt; &lt;p&gt;I can't blame InfluxData guys much, as they gotta pay their bills too. So far, we the users of OSS systems couldn't show much promise about commercial realities of the projects. Bearing OSS future only depending on donations, patrons or enterprise sponsorship is far too rare and unpredictable, even for the projects that many successful organizations heavily rely on.&lt;/p&gt; &lt;p&gt;Anyways, InfluxDB then promised and later introduced &lt;code&gt;Influx Relay&lt;/code&gt; as a complimentary consolation for missing HA parts of InfluxDB. You can get the details here and here about that. &lt;/p&gt; &lt;h2&gt;Premise&lt;/h2&gt; &lt;p&gt;For my needs, I have to try to create a reliable HA(High-Availability) setup from available free options, hence InfluxDB and the relay. It's definitely far from an InfluxDB-cluster in terms of robustness or ease of setup, but it's got the job done, at least for me.&lt;/p&gt; &lt;p&gt;I needed a setup to receive system-stats from at least 500+ instances and to store them for a while, but without breaking the bank in bills from AWS. Meaning, I could ask for and could use only couple of instances for my solution.&lt;/p&gt; &lt;p&gt;Here were my trade-offs.&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Not too many instances for this purpose. Neither, any of the heavyweight lifters e.g. AWS' m3-xlarge etc. To use only what's necessary. &lt;/li&gt; &lt;li&gt;To satisfy the budget, hence avoiding pay-per-use solutions as far as it is possible.&lt;/li&gt; &lt;li&gt;Solutions must not be crazy complex, so that handover to the DevOps team be smooth.&lt;/li&gt; &lt;li&gt;Reading the data would be too rarely w.r.t. writing. The related Grafana dashboards will be only used to investigate issues by a handful of people.&lt;/li&gt; &lt;/ul&gt; &lt;h2&gt;Overall Design&lt;/h2&gt; &lt;h3&gt;Write&lt;/h3&gt; &lt;p&gt;From a birds' eye view, I decided to use two instances to run parallelly, hosting InfluxDB on them independently and then send exactly same data over to them for storing. This scheme mostly looks like &lt;a href="https://en.wikipedia.org/wiki/Standard_RAID_levels#RAID_1"&gt;RAID-1 systems&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;&lt;img alt="Overall architecture" src="https://i.imgur.com/ZKYIyOd.png"&gt;&lt;/p&gt; &lt;p&gt;That brings up a couple of challenges.&lt;/p&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;None of the agents I used on the sender side could multiplex output. Meaning, they were able to send data to a single destination, not multiple. On the Windows front, I've used &lt;code&gt;Telegraf&lt;/code&gt; which is able randomly to switch between pre-listed destinations, but NOT multiple at-once.&lt;br&gt; In the case of Linux hosts, I used &lt;code&gt;Netdata&lt;/code&gt; which is excellent in its own right, but unable to send stats to multiple destinations.&lt;br&gt; Here comes &lt;code&gt;Influx-relay&lt;/code&gt;. It can receive time-series data-stream from hosts on a TCP or UDP port, buffer for a while, and then re-send those received and buffered data to multiple receive ends which can either be an InfluxDB instance or another listening Influx-relay instances.&lt;br&gt; This chaining can broaden the relaying scheme even further. However, for my purpose, this relay-chaining was not necessary. Rather, from the relay, I am sending data to the separate InfluxDB instances, running on two separate instances. &lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Now that I partially multiplexed the output, my hosts (senders) still are able to send to one destination. So, I need a proxy as well as a load-balancer. For a while, I was torn between NGINX and HAProxy. Both were new to me. &lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;p&gt;However, for a couple of reasons, I went for HAProxy. Firstly, I have no need for HTTP session management. Secondly, as I wanted to keep my UDP for later, HAProxy was perfectly capable of that.&lt;br&gt; NGINX has the support recently, maturity was a concern. Also, configuring NGINX seems little intimating (which I know not so true). Last but not least, and for what its worth, out-of-the-box, HAProxy's stat page carries much more in-depth information than that of free-version of NGINX.&lt;br&gt; Upon receiving the stats stream, HAProxy was supposed to send that to different Influx-relays in a load-balanced fashion.&lt;/p&gt; &lt;p&gt;So, here's my rough plan. &lt;/p&gt; &lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;collector-agent --&amp;gt; HAProxy --&amp;gt; (50/50 load-balanced) --&amp;gt; Influx-relay --&amp;gt; (multiplexed) --&amp;gt; 2 InfluxDB instances &lt;/pre&gt;&lt;/div&gt; &lt;p&gt;Now, each of the received data is to go to both the InfluxDB, or at least one in case of failure (or, overload) of any the relays or Influx instances. Â  Also, I have chosen to keep Influx-relays deployed as Dockerized and kept HAProxy and InfluxDB instances running as native services. Of course, you can Dockerize HAProxy and InfluxDB, too. &lt;/p&gt; &lt;h3&gt;Read&lt;/h3&gt; &lt;p&gt;As I've already noted in the section that reading the data, meaning to fetch data to visualize on Grafana end, will happen rarely and sporadically; only to investigate alarms or any other client-side performance issues. &lt;/p&gt; &lt;p&gt;So, the read requests, reaching the HAProxy end, needed not much routing, other than directly to InfluxDB itself. Still, to better distribute the load I decided to load-balance it 50/50 basis.&lt;/p&gt; &lt;h3&gt;Ports&lt;/h3&gt; &lt;ul&gt; &lt;li&gt;As all the READ requests are routed through &lt;code&gt;HAProxy&lt;/code&gt; running on each of the instances, to the external world only HAProxy's port should be opened for this purpose. &lt;/li&gt; &lt;li&gt;On the other hand, for WRITE requests, InfluxDBs are receiving data from relays, one of its own instance and another one on other instance, so InfluxDB should listen on its own port for WRITE requests only. But, this must be accessible only from own VPS zone, but not open to the outside world.&lt;/li&gt; &lt;li&gt;In case of HAProxy as well as InfluxDB, you can use the default ports, obviously, which is 8086 &amp;amp; 8088 respectively. Or, you can choose to go for other ports (security through obfuscation). Your call. In this writing, I'll go with the defaults.&lt;/li&gt; &lt;/ul&gt; &lt;h3&gt;Authentication, SSL&lt;/h3&gt; &lt;p&gt;You can configure SSL with your own server certificates through the HAProxy configs. You can even go for SSL from the relays to InfluxDB writes. If your sender hosts are connecting to your HAProxy through public internet, you should at least go for password-based authentication, better to utilize SSL. However, for brevity's sake, I'll skip them in this post.&lt;/p&gt; &lt;p&gt;&lt;strong&gt; Note: &lt;/strong&gt; Please bear in mind, this is an "in-progress" post; prematurely published to force me to work on it. I have the plan to add all the necessary configurations &amp;amp; commands, that I used, here.&lt;/p&gt;</content><category term="Tech"></category><category term="influxdb"></category><category term="influx-relay"></category><category term="haproxy"></category><category term="monitoring"></category><category term="computing"></category><category term="time-series"></category><category term="database"></category><category term="open-source"></category><category term="reliability"></category><category term="architecture"></category></entry><entry><title>Open Source as-if You Gonna Die Tonight</title><link href="https://blog.kmonsoor.com/open-source-as-if-you-gonna-die-tonight/" rel="alternate"><published>2015-12-22T00:00:00+06:00</published><updated>2015-12-23T00:00:00+06:00</updated><author><name>Khaled Monsoor</name></author><id>tag:blog.kmonsoor.com,2015-12-22:/open-source-as-if-you-gonna-die-tonight/</id><summary type="html">&lt;p&gt;You should open-source as-if you gonna die tonight. Literally.&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;strong&gt;&lt;em&gt;[ To keep the spirit of this post honest, I am going to publish this blog, immidiately. No &lt;strong&gt;draft&lt;/strong&gt;-ing. This post will be, I hope, under continuous improvement.&lt;br&gt; This post is &lt;a href="https://github.com/kmonsoor/blog.kmonsoor.com/edit/live/content/articles/open-your-source-as-if-you-gonna-die-tonight.md"&gt;available for edit on GitHub&lt;/a&gt;, currently in its version 0.0.6 ]&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Yes, I mean it. Literally.&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;I see too many post/comments/blogs, in different meeting-places for techies e.g. hackernews, reddit, etc., which say the same thing: &lt;/p&gt; &lt;blockquote&gt; &lt;p&gt;"I am working on &lt;strong&gt;&lt;em&gt;something&lt;/em&gt;&lt;/strong&gt; which I will open-source/publish &lt;strong&gt;&lt;em&gt;someday&lt;/em&gt;&lt;/strong&gt; after taking it &lt;strong&gt;&lt;em&gt;somewhere&lt;/em&gt;&lt;/strong&gt;."&lt;/p&gt; &lt;/blockquote&gt; &lt;p&gt;See the ambiguous sense in the words? &lt;/p&gt; &lt;p&gt;Unless the code/script/blog you are working on is something sensitive which will make a mess published a "draft" form, you should not wait for "someday". Or if you have thousands of subscribers to your blog ;)&lt;/p&gt; &lt;p&gt;Or if you decided that you will &lt;strong&gt;&lt;em&gt;never&lt;/em&gt;&lt;/strong&gt; publish it in public - that's an entirely different story.&lt;/p&gt; &lt;p&gt;If it is something of your company's code-base, commit it in your remote branch, so that your last 19 days of work isn't just gone just because you are "gone".&lt;/p&gt; &lt;p&gt;&lt;strong&gt;As human, we are far more fragile than we think.&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;I am not talking about publishing a physical book using a printing press. In that scenario, writers were supposed to write the perfect words, then type it using type-writer to avoid any handwriting-related gotchas. Then it went to the reviewer, then proofreader, then the typesetter makes a block character-by-character. Then comes printing on the paper. The writer had to be sure what he is writing about, ABSOLUTELY. Else, each of the &lt;em&gt;2000&lt;/em&gt; copies of the &lt;em&gt;first-edition&lt;/em&gt; would have the same mistakes.&lt;/p&gt; &lt;p&gt;I am also not talking about pushing the critical code in the &lt;code&gt;production&lt;/code&gt; server. That stuff should go through rigorous coding practices, code-reviews, testing etc.&lt;/p&gt; &lt;p&gt;Aside from those cases, &lt;strong&gt;this is 2015&lt;/strong&gt; - How much does each &lt;code&gt;git push origin gh-pages&lt;/code&gt; cost? How much each WordPress post update cost? Or, a single GitHub gist?&lt;/p&gt; &lt;p&gt;Publishing your stuff is free, no matter how many times you update it.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;So, why do we think about the paradigm of the printing press when we think of "publishing"?&lt;/strong&gt;&lt;/p&gt; &lt;h2&gt;Frequently shared confusions (FSQ)&lt;/h2&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;&lt;strong&gt;What if this, my thing, is just plain crap ?*&lt;em&gt;&lt;br&gt; &lt;strong&gt;A.&lt;/strong&gt; Are you sure? You never know for sure. Throw it in the wild. If it is really crap, nobody will remember or hold you responsible for it. How many crappy DaVinci paintings you know? I guess, &lt;/em&gt;&lt;/strong&gt;none.*** But the &lt;a href="https://en.wikipedia.org/wiki/Mona_Lisa"&gt;Mona Lisa&lt;/a&gt; didn't just appear from thin air. Did it?&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;strong&gt;This is my toy(or pet) project.&lt;/strong&gt;&lt;br&gt; &lt;strong&gt;A.&lt;/strong&gt; Don't be that selfish kid from the school who don't let others touch it just because. If you are having fun building something why not let others join in the fun?&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;strong&gt;This is a one-off script on this ancient &lt;em&gt;COBOL&lt;/em&gt; platform, no one is going to need it. Ever.&lt;/strong&gt;&lt;br&gt; &lt;strong&gt;A.&lt;/strong&gt; You never know. You are a human. You can't imagine what people gonna need. Throw it in a &lt;a href="https://gist.github.com/"&gt;gist&lt;/a&gt;, just include a suitable title. Add in some comments if you please. May be couple of years later, your script will save someone's job, and he can still put food on the table. You never know. &lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;strong&gt;If I publish this now some genius with free time will steal my idea and make it something grand without me.&lt;/strong&gt;&lt;br&gt; &lt;strong&gt;A.&lt;/strong&gt; Unless you are a big hot-shot with a ground-breaking idea, no one will even notice it. Most &lt;em&gt;genius'&lt;/em&gt; mind is already filled with their own to-do list. Even if they take your idea, let them. Move on. Don't be a muddy pond, rather be like a river. Rivers don't dry off due to peasants "stealing" some water. &lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;strong&gt;I haven't collected my thoughts enough to make this post a grand one yet.&lt;/strong&gt;&lt;br&gt; &lt;strong&gt;A.&lt;/strong&gt; Don't think too high yourself. Let others do that for you.&lt;br&gt; No project is born grand, and no great man born great. Your contributions is what goes ahead. You the person? Not so much. Time passed along "Romeo &amp;amp; Juliet", but Shakespeare is dead and gone. &lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;strong&gt;I am special. My words/code should be special, perfect, coherent like a pearl-necklace.&lt;/strong&gt; &lt;em&gt;(yes, we all feel like that, we just don't acknowledge it publicly.)&lt;/em&gt;&lt;br&gt; &lt;strong&gt;A.&lt;/strong&gt; No, you are not. You are not a special unique snowflake. See the previous answer.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Who the ***k are you to tell me what to do?&lt;/strong&gt;&lt;br&gt; &lt;strong&gt;A.&lt;/strong&gt; It's not about me, I am nobody. Just a open-source enthusiast who wants to see more and more open-source projects, scripts, blog-posts which haven't gone to grave with their mortal creators. I'm just sharing my own thoughts about it. &lt;strong&gt;It is your code on your own personal-pc, after all.&lt;/strong&gt;&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;h2&gt;Why should I open my source(post/thoughts/etc) tonight?&lt;/h2&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;You can literally die tonight. Then all of your pet-projects are just gone. 'Cause probably none in your family is in coding business or they aren't sure about your intention. &lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Tomorrow morning, your mind will just drift-away.&lt;br&gt; What is a vivid idea tonight that could impact thousands of people's lives, tomorrow morning will become a faded, will-do-it-someday idea. One month after tonight, you probably will probably be oblivious about your own idea, draft, script, code.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;It's a mind-trick to force ourselves to work on something to avoid public shame. We feel obliged to correct errata that is in public, but something hidden away in a private, hidden, local folder we don't have to feel bad about. &lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;h2&gt;To avoid embarrassment&lt;/h2&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;Make sure your audience (or colleagues for that matter) know the content's status. Put a "prelude" section mentioning the half-done condition. Better yet, use some &lt;a href="http://semver.org/"&gt;version number&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Make your genereal idea clear. For code, point out what it is and what it is supposed to do. For a blog, present the basic idea at least, even if it is not with perfect grammer.&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;h2&gt;How infrastructure can improve&lt;/h2&gt; &lt;p&gt;Open-source mainstream hosting platforms e.g. Github, Bitbucket, GitLab etc. could have a &lt;strong&gt;"Open the source"&lt;/strong&gt; trigger-switch for individual projects where a software developer can enable the trigger with some condition like:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;"&lt;strong&gt;Open the source&lt;/strong&gt;" if I don't login GitHub for &lt;code&gt;1 year&lt;/code&gt; (which means I am dead or I've gone crazy trying to remember GitHub)&lt;/li&gt; &lt;li&gt;"&lt;strong&gt;Open the source&lt;/strong&gt;" on a pre-set date e.g. &lt;code&gt;2020-02-20&lt;/code&gt;&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&lt;em&gt;[dear reader, thanks a lot for reading up to here. I am sure there are many points missing on this post. Also, as English is not my first language, hence there must some misused words or phrase. But you get the idea. Please comment/criticise/point out the missing stuff. I will try to discuss, update, correct that.]&lt;/em&gt;&lt;/p&gt; &lt;hr&gt; &lt;h2&gt;Contributors&lt;/h2&gt; &lt;table&gt; &lt;thead&gt; &lt;tr&gt; &lt;th&gt;&lt;/th&gt; &lt;th&gt;&lt;/th&gt; &lt;/tr&gt; &lt;/thead&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;&lt;a href="https://github.com/kmonsoor"&gt;Khaled Monsoor&lt;/a&gt;&lt;/td&gt; &lt;td&gt;initial author, maintainer&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;a href="https://github.com/waynew"&gt;Wayne Werner&lt;/a&gt;&lt;/td&gt; &lt;td&gt;editor (v.0.0.3 --&amp;gt; v.0.0.4)&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2&gt;Some related inspirations from some open-source jedis&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href="https://rhettinger.wordpress.com/2011/01/28/open-your-source-more/"&gt;Raymond Hettinger :: Open Source Challenge: Open Your Source, More&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://www.jeffknupp.com/blog/2013/08/16/open-sourcing-a-python-project-the-right-way/"&gt;Jeff Knupp :: Open Sourcing a Python Project the Right Way&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://archive.org/stream/GuerillaOpenAccessManifesto/Goamjuly2008_djvu.txt"&gt;Aaron Swartz :: Guerilla Open Access Manifesto&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt;</content><category term="Tech"></category><category term="coding"></category><category term="open-source"></category><category term="OSS"></category><category term="death"></category><category term="bus-factor"></category><category term="truck-factor"></category><category term="source-control"></category><category term="software"></category><category term="personal"></category><category term="projects"></category></entry></feed>